{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StormParse PDF Parsing Tutorial\n",
    "\n",
    "This interactive notebook demonstrates how to use the StormParse API for PDF document parsing with practical examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, let's import the necessary libraries and set up our API configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/sigridjineth/Desktop/work/storm-parse-example/storm-parse/cookbook/.venv/lib/python3.11/site-packages (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/sigridjineth/Desktop/work/storm-parse-example/storm-parse/cookbook/.venv/lib/python3.11/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sigridjineth/Desktop/work/storm-parse-example/storm-parse/cookbook/.venv/lib/python3.11/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sigridjineth/Desktop/work/storm-parse-example/storm-parse/cookbook/.venv/lib/python3.11/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sigridjineth/Desktop/work/storm-parse-example/storm-parse/cookbook/.venv/lib/python3.11/site-packages (from requests) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ API configured for: https://live-storm-apis-parse-router.sionic.im\n",
      "‚úÖ Using API key: demo_Kx8fH...\n"
     ]
    }
   ],
   "source": [
    "%pip install requests\n",
    "\n",
    "# Import required libraries\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Configuration\n",
    "# StormParse API configuration\n",
    "API_BASE_URL = \"https://live-storm-apis-parse-router.sionic.im\"\n",
    "API_KEY = \"demo-test\"  # Replace with your API key\n",
    "\n",
    "# Headers with authorization\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {API_KEY}',\n",
    "    'Accept': '*/*'\n",
    "}\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    # Note: The base URL might not accept GET requests, so we'll skip the test\n",
    "    print(f\"‚úÖ API configured for: {API_BASE_URL}\")\n",
    "    print(f\"‚úÖ Using API key: {API_KEY[:10]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Configuration loaded. API URL: {API_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Let's define some helper functions that we'll use throughout the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def upload_document(file_path, api_key=API_KEY, api_base_url=API_BASE_URL):\n",
    "    \"\"\"Upload a document to StormParse API.\"\"\"\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {api_key}',\n",
    "        'Accept': '*/*'\n",
    "    }\n",
    "    \n",
    "    with open(file_path, 'rb') as f:\n",
    "        files = {'file': f}\n",
    "        response = requests.post(f\"{api_base_url}/api/v1/parsing/upload\", files=files, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Upload failed with status {response.status_code}\")\n",
    "    \n",
    "    result = response.json()\n",
    "    if result['result_type'] != 'SUCCESS':\n",
    "        raise Exception(f\"Upload error: {result['error']}\")\n",
    "    \n",
    "    return result['success']['job_id']\n",
    "\n",
    "def wait_for_job(job_id, api_key=API_KEY, api_base_url=API_BASE_URL, timeout=300):\n",
    "    \"\"\"Wait for a parsing job to complete.\"\"\"\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {api_key}',\n",
    "        'Accept': '*/*'\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    while time.time() - start_time < timeout:\n",
    "        response = requests.get(f\"{api_base_url}/api/v1/parsing/job/{job_id}\", headers=headers)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Status check failed with status {response.status_code}\")\n",
    "        \n",
    "        result = response.json()\n",
    "        if result['result_type'] != 'SUCCESS':\n",
    "            raise Exception(f\"Status error: {result['error']}\")\n",
    "        \n",
    "        data = result['success']\n",
    "        \n",
    "        if data['state'] == 'COMPLETED':\n",
    "            return data['pages']\n",
    "        elif data['state'] == 'FAILED':\n",
    "            raise Exception(\"Parsing job failed\")\n",
    "        \n",
    "        time.sleep(2)\n",
    "    \n",
    "    raise Exception(f\"Timeout after {timeout} seconds\")\n",
    "\n",
    "def parse_document(file_path, api_key=API_KEY, api_base_url=API_BASE_URL):\n",
    "    \"\"\"Upload and parse a document, returning the pages.\"\"\"\n",
    "    print(f\"Uploading: {file_path}\")\n",
    "    job_id = upload_document(file_path, api_key, api_base_url)\n",
    "    print(f\"Job ID: {job_id}\")\n",
    "    \n",
    "    print(\"Waiting for completion...\", end=\"\")\n",
    "    pages = wait_for_job(job_id, api_key, api_base_url)\n",
    "    print(\" ‚úÖ Done!\")\n",
    "    \n",
    "    return pages\n",
    "\n",
    "print(\"Helper functions loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic PDF Parsing\n",
    "\n",
    "Let's start with a simple example of parsing a PDF document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading: ../99_example_docs/ÏÇºÏÑ± Ïû¨Î¨¥Ï†úÌëú.pdf\n",
      "Job ID: 6090af87-c73f-47fa-95e9-35e267fbe30d\n",
      "Waiting for completion... ‚úÖ Done!\n",
      "\n",
      "‚úÖ Successfully parsed 2 pages\n",
      "üìä Total characters: 3,875\n",
      "üìä Total words: 587\n",
      "üìä Average words per page: 293\n"
     ]
    }
   ],
   "source": [
    "def parse_simple_pdf(file_path):\n",
    "    \"\"\"Parse a PDF and display basic information.\"\"\"\n",
    "    try:\n",
    "        pages = parse_document(file_path)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Successfully parsed {len(pages)} pages\")\n",
    "        \n",
    "        # Show statistics\n",
    "        total_chars = sum(len(page['content']) for page in pages)\n",
    "        total_words = sum(len(page['content'].split()) for page in pages)\n",
    "        \n",
    "        print(f\"üìä Total characters: {total_chars:,}\")\n",
    "        print(f\"üìä Total words: {total_words:,}\")\n",
    "        print(f\"üìä Average words per page: {total_words // len(pages) if pages else 0:,}\")\n",
    "        \n",
    "        return pages\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error parsing PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test with actual PDF files from 99_example_docs directory\n",
    "# Available PDFs:\n",
    "# - ÏÇºÏÑ± Ïû¨Î¨¥Ï†úÌëú.pdf (Samsung Financial Statement)\n",
    "# - ÏÇºÏÑ± Ï≤≠ÏÜåÍ∏∞ ÌÄµ Í∞ÄÏù¥Îìú.pdf (Samsung Vacuum Cleaner Quick Guide)  \n",
    "# - Ïã†ÎùºÏä§ÌÖåÏù¥_Ïó¨Ïàò_Ìò∏ÌÖîÏïàÎÇ¥ÏûêÎ£å.pdf (Shilla Stay Yeosu Hotel Information)\n",
    "\n",
    "sample_pdf = \"../99_example_docs/ÏÇºÏÑ± Ïû¨Î¨¥Ï†úÌëú.pdf\"\n",
    "pages = parse_simple_pdf(sample_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Display Page Content\n",
    "\n",
    "Let's examine the content of individual pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Page 1 Content:\n",
      "============================================================\n",
      "Ïù¥ Î¨∏ÏÑúÎäî ÏÇºÏÑ±Ï†ÑÏûêÏ£ºÏãùÌöåÏÇ¨ÏôÄ Í∑∏ Ï¢ÖÏÜçÍ∏∞ÏóÖÏùò Ïó∞Í≤∞Ïû¨Î¨¥ÏÉÅÌÉúÌëúÎ•º ÎÇòÌÉÄÎÉÖÎãàÎã§. Ï†ú54Í∏∞Îäî 2022ÎÖÑ 12Ïõî 31Ïùº ÌòÑÏû¨Ïù¥Î©∞, Ï†ú53Í∏∞Îäî 2021ÎÖÑ 12Ïõî 31Ïùº ÌòÑÏû¨ Í∏∞Ï§ÄÏûÖÎãàÎã§. Î™®Îì† Í∏àÏï°Ïùò Îã®ÏúÑÎäî Î∞±ÎßåÏõêÏûÖÎãàÎã§.\n",
      "\n",
      "Ïù¥ ÌëúÎäî ÏûêÏÇ∞Í≥º Î∂ÄÏ±Ñ Ìï≠Î™©ÏùÑ Ï†ú54Í∏∞(ÎãπÍ∏∞)ÏôÄ Ï†ú53Í∏∞(Ï†ÑÍ∏∞)Î°ú ÎÇòÎàÑÏñ¥ ÎπÑÍµêÌïòÏó¨ Î≥¥Ïó¨Ï§çÎãàÎã§. Í∞Å Ìï≠Î™© ÏòÜÏóêÎäî Í¥ÄÎ†® Ï£ºÏÑù Î≤àÌò∏Í∞Ä Í∏∞Ïû¨ÎêòÏñ¥ ÏûàÏäµÎãàÎã§.\n",
      "\n",
      "### ÏûêÏÇ∞\n",
      "\n",
      "#### I. Ïú†ÎèôÏûêÏÇ∞\n",
      "\n",
      "Ïú†ÎèôÏûêÏÇ∞Ïùò Ï¥ùÏï°ÏùÄ Ï†ú54Í∏∞ 218,470,581Î∞±ÎßåÏõêÏúºÎ°ú, Ï†ú53Í∏∞ 218,163,185Î∞±ÎßåÏõêÏóê ÎπÑÌï¥ ÏÜåÌè≠ Ï¶ùÍ∞ÄÌñàÏäµÎãàÎã§. Íµ¨Ï≤¥Ï†ÅÏù∏ Ìï≠Î™©Î≥Ñ Í∏àÏï°ÏùÄ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§.\n",
      "1.  ÌòÑÍ∏àÎ∞èÌòÑÍ∏àÏÑ±ÏûêÏÇ∞(Ï£ºÏÑù 4, 28): Ï†ú54Í∏∞ 49,680,710Î∞±ÎßåÏõê, Ï†ú53Í∏∞ 39,031,415Î∞±ÎßåÏõêÏûÖÎãàÎã§.\n",
      "2.  Îã®Í∏∞Í∏àÏúµÏÉÅÌíà(Ï£ºÏÑù 4, 28): Ï†ú54Í∏∞ 65,102,886Î∞±ÎßåÏõê, Ï†ú53Í∏∞ 81,708,986Î∞±ÎßåÏõêÏûÖÎãàÎã§.\n",
      "3.  Îã®Í∏∞ÏÉÅÍ∞ÅÌõÑÏõêÍ∞ÄÍ∏àÏúµÏûêÏÇ∞(Ï£ºÏÑù 4, 28): Ï†ú54Í∏∞ 414,610Î∞±ÎßåÏõê, Ï†ú53Í∏∞ 3,369,0...\n",
      "\n",
      "[Showing first 500 characters of 2547 total]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def display_page_content(pages, page_num=1, preview_length=500):\n",
    "    \"\"\"Display content from a specific page.\"\"\"\n",
    "    if not pages:\n",
    "        print(\"No pages to display\")\n",
    "        return\n",
    "    \n",
    "    if page_num > len(pages) or page_num < 1:\n",
    "        print(f\"Invalid page number. Document has {len(pages)} pages.\")\n",
    "        return\n",
    "    \n",
    "    page = pages[page_num - 1]\n",
    "    \n",
    "    print(f\"\\nüìÑ Page {page['pageNumber']} Content:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    content = page['content']\n",
    "    \n",
    "    # Show preview or full content\n",
    "    if len(content) > preview_length:\n",
    "        print(content[:preview_length] + \"...\")\n",
    "        print(f\"\\n[Showing first {preview_length} characters of {len(content)} total]\")\n",
    "    else:\n",
    "        print(content)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Display first page content from the parsed PDF\n",
    "if 'pages' in globals() and pages:\n",
    "    display_page_content(pages, page_num=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Batch Processing Multiple PDFs\n",
    "\n",
    "Process multiple PDF files from a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Processing and saving all PDFs as text files...\n",
      "\n",
      "üìÅ Found 3 PDF files to process\n",
      "  ‚Ä¢ ·Ñâ·Ö°·Ü∑·Ñâ·Ö•·Üº ·Ñé·Ö•·Üº·Ñâ·Ö©·ÑÄ·Öµ ·Ñè·Ö±·Ü® ·ÑÄ·Ö°·Ñã·Öµ·ÑÉ·Ö≥.pdf\n",
      "  ‚Ä¢ ·Ñâ·Öµ·Ü´·ÑÖ·Ö°·Ñâ·Ö≥·Ñê·Ö¶·Ñã·Öµ_·Ñã·Öß·Ñâ·ÖÆ_·Ñí·Ö©·Ñê·Ö¶·ÜØ·Ñã·Ö°·Ü´·ÑÇ·Ö¢·Ñå·Ö°·ÑÖ·Ö≠.pdf\n",
      "  ‚Ä¢ ·Ñâ·Ö°·Ü∑·Ñâ·Ö•·Üº ·Ñå·Ö¢·ÑÜ·ÖÆ·Ñå·Ö¶·Ñë·Ö≠.pdf\n",
      "\n",
      "‚è≥ Processing and saving PDFs...\n",
      "Uploading: ../99_example_docs/·Ñâ·Ö°·Ü∑·Ñâ·Ö•·Üº ·Ñé·Ö•·Üº·Ñâ·Ö©·ÑÄ·Öµ ·Ñè·Ö±·Ü® ·ÑÄ·Ö°·Ñã·Öµ·ÑÉ·Ö≥.pdf\n",
      "Uploading: ../99_example_docs/·Ñâ·Öµ·Ü´·ÑÖ·Ö°·Ñâ·Ö≥·Ñê·Ö¶·Ñã·Öµ_·Ñã·Öß·Ñâ·ÖÆ_·Ñí·Ö©·Ñê·Ö¶·ÜØ·Ñã·Ö°·Ü´·ÑÇ·Ö¢·Ñå·Ö°·ÑÖ·Ö≠.pdf\n",
      "Uploading: ../99_example_docs/·Ñâ·Ö°·Ü∑·Ñâ·Ö•·Üº ·Ñå·Ö¢·ÑÜ·ÖÆ·Ñå·Ö¶·Ñë·Ö≠.pdf\n",
      "Job ID: 3a65adde-c803-4df5-b1b3-ca169098ad49\n",
      "Waiting for completion...Job ID: bad2668c-4e91-425f-9798-71bd8153d0fe\n",
      "Waiting for completion...Job ID: 1f588a35-792a-438c-bad7-526459fcad0e\n",
      "Waiting for completion... ‚úÖ Done!\n",
      "‚úÖ Saved as text: ·Ñâ·Öµ·Ü´·ÑÖ·Ö°·Ñâ·Ö≥·Ñê·Ö¶·Ñã·Öµ_·Ñã·Öß·Ñâ·ÖÆ_·Ñí·Ö©·Ñê·Ö¶·ÜØ·Ñã·Ö°·Ü´·ÑÇ·Ö¢·Ñå·Ö°·ÑÖ·Ö≠_parsed_20250806_182406.txt\n",
      "  ‚úÖ ·Ñâ·Öµ·Ü´·ÑÖ·Ö°·Ñâ·Ö≥·Ñê·Ö¶·Ñã·Öµ_·Ñã·Öß·Ñâ·ÖÆ_·Ñí·Ö©·Ñê·Ö¶·ÜØ·Ñã·Ö°·Ü´·ÑÇ·Ö¢·Ñå·Ö°·ÑÖ·Ö≠.pdf: 14 pages, 3,223 words\n",
      "      ‚Üí Saved as: ·Ñâ·Öµ·Ü´·ÑÖ·Ö°·Ñâ·Ö≥·Ñê·Ö¶·Ñã·Öµ_·Ñã·Öß·Ñâ·ÖÆ_·Ñí·Ö©·Ñê·Ö¶·ÜØ·Ñã·Ö°·Ü´·ÑÇ·Ö¢·Ñå·Ö°·ÑÖ·Ö≠_parsed_20250806_182406.txt\n",
      " ‚úÖ Done!\n",
      "‚úÖ Saved as text: ·Ñâ·Ö°·Ü∑·Ñâ·Ö•·Üº ·Ñå·Ö¢·ÑÜ·ÖÆ·Ñå·Ö¶·Ñë·Ö≠_parsed_20250806_182410.txt\n",
      "  ‚úÖ ·Ñâ·Ö°·Ü∑·Ñâ·Ö•·Üº ·Ñå·Ö¢·ÑÜ·ÖÆ·Ñå·Ö¶·Ñë·Ö≠.pdf: 2 pages, 679 words\n",
      "      ‚Üí Saved as: ·Ñâ·Ö°·Ü∑·Ñâ·Ö•·Üº ·Ñå·Ö¢·ÑÜ·ÖÆ·Ñå·Ö¶·Ñë·Ö≠_parsed_20250806_182410.txt\n",
      " ‚úÖ Done!\n",
      "‚úÖ Saved as text: ·Ñâ·Ö°·Ü∑·Ñâ·Ö•·Üº ·Ñé·Ö•·Üº·Ñâ·Ö©·ÑÄ·Öµ ·Ñè·Ö±·Ü® ·ÑÄ·Ö°·Ñã·Öµ·ÑÉ·Ö≥_parsed_20250806_182414.txt\n",
      "  ‚úÖ ·Ñâ·Ö°·Ü∑·Ñâ·Ö•·Üº ·Ñé·Ö•·Üº·Ñâ·Ö©·ÑÄ·Öµ ·Ñè·Ö±·Ü® ·ÑÄ·Ö°·Ñã·Öµ·ÑÉ·Ö≥.pdf: 2 pages, 1,974 words\n",
      "      ‚Üí Saved as: ·Ñâ·Ö°·Ü∑·Ñâ·Ö•·Üº ·Ñé·Ö•·Üº·Ñâ·Ö©·ÑÄ·Öµ ·Ñè·Ö±·Ü® ·ÑÄ·Ö°·Ñã·Öµ·ÑÉ·Ö≥_parsed_20250806_182414.txt\n",
      "\n",
      "üìä Batch Processing Summary:\n",
      "  ‚Ä¢ Processed: 3/3 PDFs successfully\n",
      "  ‚Ä¢ Total pages: 18\n",
      "  ‚Ä¢ Total words: 5,876\n",
      "\n",
      "üíæ Saved Files:\n",
      "  ‚Ä¢ ·Ñâ·Öµ·Ü´·ÑÖ·Ö°·Ñâ·Ö≥·Ñê·Ö¶·Ñã·Öµ_·Ñã·Öß·Ñâ·ÖÆ_·Ñí·Ö©·Ñê·Ö¶·ÜØ·Ñã·Ö°·Ü´·ÑÇ·Ö¢·Ñå·Ö°·ÑÖ·Ö≠_parsed_20250806_182406.txt\n",
      "  ‚Ä¢ ·Ñâ·Ö°·Ü∑·Ñâ·Ö•·Üº ·Ñå·Ö¢·ÑÜ·ÖÆ·Ñå·Ö¶·Ñë·Ö≠_parsed_20250806_182410.txt\n",
      "  ‚Ä¢ ·Ñâ·Ö°·Ü∑·Ñâ·Ö•·Üº ·Ñé·Ö•·Üº·Ñâ·Ö©·ÑÄ·Öµ ·Ñè·Ö±·Ü® ·ÑÄ·Ö°·Ñã·Öµ·ÑÉ·Ö≥_parsed_20250806_182414.txt\n",
      "‚úÖ Combined all PDFs into: all_pdfs_combined_20250806_182414.txt\n"
     ]
    }
   ],
   "source": [
    "def batch_process_and_save_pdfs(directory_path, max_workers=3, api_key=API_KEY, api_base_url=API_BASE_URL, save_format='txt'):\n",
    "    \"\"\"Process all PDFs in a directory and save each one.\"\"\"\n",
    "    # Check if directory exists\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"Directory not found: {directory_path}\")\n",
    "        return {}\n",
    "    \n",
    "    # Find all PDF files\n",
    "    pdf_files = [\n",
    "        os.path.join(directory_path, f)\n",
    "        for f in os.listdir(directory_path)\n",
    "        if f.lower().endswith('.pdf')\n",
    "    ]\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(f\"No PDF files found in {directory_path}\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"\\nüìÅ Found {len(pdf_files)} PDF files to process\")\n",
    "    for pdf in pdf_files:\n",
    "        print(f\"  ‚Ä¢ {os.path.basename(pdf)}\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    def process_and_save_single_pdf(file_path):\n",
    "        \"\"\"Process a single PDF file and save it.\"\"\"\n",
    "        try:\n",
    "            # Parse the document\n",
    "            pages = parse_document(file_path, api_key, api_base_url)\n",
    "            \n",
    "            # Save the parsed content\n",
    "            base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            saved_file = save_parsed_content(pages, base_name, save_format)\n",
    "            \n",
    "            return {\n",
    "                'status': 'success',\n",
    "                'file': os.path.basename(file_path),\n",
    "                'pages': len(pages),\n",
    "                'words': sum(len(p['content'].split()) for p in pages),\n",
    "                'chars': sum(len(p['content']) for p in pages),\n",
    "                'saved_as': saved_file,\n",
    "                'content': pages  # Store the actual content if needed\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'file': os.path.basename(file_path),\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    # Process PDFs concurrently\n",
    "    print(\"\\n‚è≥ Processing and saving PDFs...\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_file = {\n",
    "            executor.submit(process_and_save_single_pdf, pdf): pdf\n",
    "            for pdf in pdf_files\n",
    "        }\n",
    "        \n",
    "        for future in as_completed(future_to_file):\n",
    "            result = future.result()\n",
    "            results[result['file']] = result\n",
    "            \n",
    "            # Show progress\n",
    "            if result['status'] == 'success':\n",
    "                print(f\"  ‚úÖ {result['file']}: {result['pages']} pages, {result['words']:,} words\")\n",
    "                print(f\"      ‚Üí Saved as: {result['saved_as']}\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå {result['file']}: {result['error']}\")\n",
    "    \n",
    "    # Summary\n",
    "    successful = sum(1 for r in results.values() if r['status'] == 'success')\n",
    "    total_pages = sum(r.get('pages', 0) for r in results.values())\n",
    "    total_words = sum(r.get('words', 0) for r in results.values())\n",
    "    \n",
    "    print(f\"\\nüìä Batch Processing Summary:\")\n",
    "    print(f\"  ‚Ä¢ Processed: {successful}/{len(pdf_files)} PDFs successfully\")\n",
    "    print(f\"  ‚Ä¢ Total pages: {total_pages:,}\")\n",
    "    print(f\"  ‚Ä¢ Total words: {total_words:,}\")\n",
    "    print(f\"\\nüíæ Saved Files:\")\n",
    "    for result in results.values():\n",
    "        if result['status'] == 'success' and 'saved_as' in result:\n",
    "            print(f\"  ‚Ä¢ {result['saved_as']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Process and save all PDFs in multiple formats\n",
    "def batch_process_all_formats(directory_path, api_key=API_KEY):\n",
    "    \"\"\"Process PDFs and save in all available formats.\"\"\"\n",
    "    formats = ['txt', 'json', 'md']\n",
    "    all_results = {}\n",
    "    \n",
    "    for fmt in formats:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üìÑ Saving all PDFs as {fmt.upper()} format\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        results = batch_process_and_save_pdfs(\n",
    "            directory_path, \n",
    "            max_workers=3, \n",
    "            api_key=api_key,\n",
    "            save_format=fmt\n",
    "        )\n",
    "        all_results[fmt] = results\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Example usage: Process and save all PDFs\n",
    "example_dir = \"../99_example_docs\"\n",
    "\n",
    "# Option 1: Save all as text files\n",
    "print(\"\\nüöÄ Processing and saving all PDFs as text files...\")\n",
    "results_txt = batch_process_and_save_pdfs(example_dir, api_key=API_KEY, save_format='txt')\n",
    "\n",
    "# Option 2: Save all in multiple formats (uncomment to use)\n",
    "# print(\"\\nüöÄ Processing and saving all PDFs in all formats...\")\n",
    "# all_format_results = batch_process_all_formats(example_dir, api_key=API_KEY)\n",
    "\n",
    "# Function to save all PDFs combined into one file\n",
    "def save_all_pdfs_combined(results, output_filename=\"all_pdfs_combined\"):\n",
    "    \"\"\"Combine all successfully parsed PDFs into a single file.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = f\"{output_filename}_{timestamp}.txt\"\n",
    "    \n",
    "    successful_pdfs = [r for r in results.values() if r['status'] == 'success' and 'content' in r]\n",
    "    \n",
    "    if not successful_pdfs:\n",
    "        print(\"No successfully parsed PDFs to combine\")\n",
    "        return None\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"# Combined PDF Documents\\n\")\n",
    "        f.write(f\"# Parsed on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"# Total documents: {len(successful_pdfs)}\\n\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        for result in successful_pdfs:\n",
    "            f.write(f\"\\n{'='*80}\\n\")\n",
    "            f.write(f\"DOCUMENT: {result['file']}\\n\")\n",
    "            f.write(f\"Pages: {result['pages']}, Words: {result['words']:,}\\n\")\n",
    "            f.write(f\"{'='*80}\\n\\n\")\n",
    "            \n",
    "            for page in result['content']:\n",
    "                f.write(f\"--- Page {page['pageNumber']} ---\\n\")\n",
    "                f.write(page['content'])\n",
    "                f.write(\"\\n\\n\")\n",
    "    \n",
    "    print(f\"‚úÖ Combined all PDFs into: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "# Combine all successfully parsed PDFs (if you want a single combined file)\n",
    "if results_txt:\n",
    "    combined_file = save_all_pdfs_combined(results_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
