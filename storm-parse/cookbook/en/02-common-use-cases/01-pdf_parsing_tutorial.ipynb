{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StormParse PDF Parsing Tutorial\n",
    "\n",
    "This interactive notebook demonstrates how to use the StormParse API for PDF document parsing with practical examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, let's import the necessary libraries and set up our API configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/sigridjineth/Desktop/work/storm-parse-example/storm-parse/cookbook/.venv/lib/python3.11/site-packages (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/sigridjineth/Desktop/work/storm-parse-example/storm-parse/cookbook/.venv/lib/python3.11/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sigridjineth/Desktop/work/storm-parse-example/storm-parse/cookbook/.venv/lib/python3.11/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sigridjineth/Desktop/work/storm-parse-example/storm-parse/cookbook/.venv/lib/python3.11/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sigridjineth/Desktop/work/storm-parse-example/storm-parse/cookbook/.venv/lib/python3.11/site-packages (from requests) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "✅ API configured for: https://live-storm-apis-parse-router.sionic.im\n",
      "✅ Using API key: demo_Kx8fH...\n"
     ]
    }
   ],
   "source": [
    "%pip install requests\n",
    "\n",
    "# Import required libraries\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Configuration\n",
    "# StormParse API configuration\n",
    "API_BASE_URL = \"https://live-storm-apis-parse-router.sionic.im\"\n",
    "API_KEY = \"demo-test\"  # Replace with your API key\n",
    "\n",
    "# Headers with authorization\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {API_KEY}',\n",
    "    'Accept': '*/*'\n",
    "}\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    # Note: The base URL might not accept GET requests, so we'll skip the test\n",
    "    print(f\"✅ API configured for: {API_BASE_URL}\")\n",
    "    print(f\"✅ Using API key: {API_KEY[:10]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Configuration loaded. API URL: {API_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Let's define some helper functions that we'll use throughout the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def upload_document(file_path, api_key=API_KEY, api_base_url=API_BASE_URL):\n",
    "    \"\"\"Upload a document to StormParse API.\"\"\"\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {api_key}',\n",
    "        'Accept': '*/*'\n",
    "    }\n",
    "    \n",
    "    with open(file_path, 'rb') as f:\n",
    "        files = {'file': f}\n",
    "        response = requests.post(f\"{api_base_url}/api/v1/parsing/upload\", files=files, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Upload failed with status {response.status_code}\")\n",
    "    \n",
    "    result = response.json()\n",
    "    if result['result_type'] != 'SUCCESS':\n",
    "        raise Exception(f\"Upload error: {result['error']}\")\n",
    "    \n",
    "    return result['success']['job_id']\n",
    "\n",
    "def wait_for_job(job_id, api_key=API_KEY, api_base_url=API_BASE_URL, timeout=300):\n",
    "    \"\"\"Wait for a parsing job to complete.\"\"\"\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {api_key}',\n",
    "        'Accept': '*/*'\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    while time.time() - start_time < timeout:\n",
    "        response = requests.get(f\"{api_base_url}/api/v1/parsing/job/{job_id}\", headers=headers)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Status check failed with status {response.status_code}\")\n",
    "        \n",
    "        result = response.json()\n",
    "        if result['result_type'] != 'SUCCESS':\n",
    "            raise Exception(f\"Status error: {result['error']}\")\n",
    "        \n",
    "        data = result['success']\n",
    "        \n",
    "        if data['state'] == 'COMPLETED':\n",
    "            return data['pages']\n",
    "        elif data['state'] == 'FAILED':\n",
    "            raise Exception(\"Parsing job failed\")\n",
    "        \n",
    "        time.sleep(2)\n",
    "    \n",
    "    raise Exception(f\"Timeout after {timeout} seconds\")\n",
    "\n",
    "def parse_document(file_path, api_key=API_KEY, api_base_url=API_BASE_URL):\n",
    "    \"\"\"Upload and parse a document, returning the pages.\"\"\"\n",
    "    print(f\"Uploading: {file_path}\")\n",
    "    job_id = upload_document(file_path, api_key, api_base_url)\n",
    "    print(f\"Job ID: {job_id}\")\n",
    "    \n",
    "    print(\"Waiting for completion...\", end=\"\")\n",
    "    pages = wait_for_job(job_id, api_key, api_base_url)\n",
    "    print(\" ✅ Done!\")\n",
    "    \n",
    "    return pages\n",
    "\n",
    "print(\"Helper functions loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic PDF Parsing\n",
    "\n",
    "Let's start with a simple example of parsing a PDF document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading: ../99_example_docs/삼성 재무제표.pdf\n",
      "Job ID: 6090af87-c73f-47fa-95e9-35e267fbe30d\n",
      "Waiting for completion... ✅ Done!\n",
      "\n",
      "✅ Successfully parsed 2 pages\n",
      "📊 Total characters: 3,875\n",
      "📊 Total words: 587\n",
      "📊 Average words per page: 293\n"
     ]
    }
   ],
   "source": [
    "def parse_simple_pdf(file_path):\n",
    "    \"\"\"Parse a PDF and display basic information.\"\"\"\n",
    "    try:\n",
    "        pages = parse_document(file_path)\n",
    "        \n",
    "        print(f\"\\n✅ Successfully parsed {len(pages)} pages\")\n",
    "        \n",
    "        # Show statistics\n",
    "        total_chars = sum(len(page['content']) for page in pages)\n",
    "        total_words = sum(len(page['content'].split()) for page in pages)\n",
    "        \n",
    "        print(f\"📊 Total characters: {total_chars:,}\")\n",
    "        print(f\"📊 Total words: {total_words:,}\")\n",
    "        print(f\"📊 Average words per page: {total_words // len(pages) if pages else 0:,}\")\n",
    "        \n",
    "        return pages\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error parsing PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test with actual PDF files from 99_example_docs directory\n",
    "# Available PDFs:\n",
    "# - 삼성 재무제표.pdf (Samsung Financial Statement)\n",
    "# - 삼성 청소기 퀵 가이드.pdf (Samsung Vacuum Cleaner Quick Guide)  \n",
    "# - 신라스테이_여수_호텔안내자료.pdf (Shilla Stay Yeosu Hotel Information)\n",
    "\n",
    "sample_pdf = \"../99_example_docs/삼성 재무제표.pdf\"\n",
    "pages = parse_simple_pdf(sample_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Display Page Content\n",
    "\n",
    "Let's examine the content of individual pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Page 1 Content:\n",
      "============================================================\n",
      "이 문서는 삼성전자주식회사와 그 종속기업의 연결재무상태표를 나타냅니다. 제54기는 2022년 12월 31일 현재이며, 제53기는 2021년 12월 31일 현재 기준입니다. 모든 금액의 단위는 백만원입니다.\n",
      "\n",
      "이 표는 자산과 부채 항목을 제54기(당기)와 제53기(전기)로 나누어 비교하여 보여줍니다. 각 항목 옆에는 관련 주석 번호가 기재되어 있습니다.\n",
      "\n",
      "### 자산\n",
      "\n",
      "#### I. 유동자산\n",
      "\n",
      "유동자산의 총액은 제54기 218,470,581백만원으로, 제53기 218,163,185백만원에 비해 소폭 증가했습니다. 구체적인 항목별 금액은 다음과 같습니다.\n",
      "1.  현금및현금성자산(주석 4, 28): 제54기 49,680,710백만원, 제53기 39,031,415백만원입니다.\n",
      "2.  단기금융상품(주석 4, 28): 제54기 65,102,886백만원, 제53기 81,708,986백만원입니다.\n",
      "3.  단기상각후원가금융자산(주석 4, 28): 제54기 414,610백만원, 제53기 3,369,0...\n",
      "\n",
      "[Showing first 500 characters of 2547 total]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def display_page_content(pages, page_num=1, preview_length=500):\n",
    "    \"\"\"Display content from a specific page.\"\"\"\n",
    "    if not pages:\n",
    "        print(\"No pages to display\")\n",
    "        return\n",
    "    \n",
    "    if page_num > len(pages) or page_num < 1:\n",
    "        print(f\"Invalid page number. Document has {len(pages)} pages.\")\n",
    "        return\n",
    "    \n",
    "    page = pages[page_num - 1]\n",
    "    \n",
    "    print(f\"\\n📄 Page {page['pageNumber']} Content:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    content = page['content']\n",
    "    \n",
    "    # Show preview or full content\n",
    "    if len(content) > preview_length:\n",
    "        print(content[:preview_length] + \"...\")\n",
    "        print(f\"\\n[Showing first {preview_length} characters of {len(content)} total]\")\n",
    "    else:\n",
    "        print(content)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Display first page content from the parsed PDF\n",
    "if 'pages' in globals() and pages:\n",
    "    display_page_content(pages, page_num=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Batch Processing Multiple PDFs\n",
    "\n",
    "Process multiple PDF files from a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Processing and saving all PDFs as text files...\n",
      "\n",
      "📁 Found 3 PDF files to process\n",
      "  • 삼성 청소기 퀵 가이드.pdf\n",
      "  • 신라스테이_여수_호텔안내자료.pdf\n",
      "  • 삼성 재무제표.pdf\n",
      "\n",
      "⏳ Processing and saving PDFs...\n",
      "Uploading: ../99_example_docs/삼성 청소기 퀵 가이드.pdf\n",
      "Uploading: ../99_example_docs/신라스테이_여수_호텔안내자료.pdf\n",
      "Uploading: ../99_example_docs/삼성 재무제표.pdf\n",
      "Job ID: 3a65adde-c803-4df5-b1b3-ca169098ad49\n",
      "Waiting for completion...Job ID: bad2668c-4e91-425f-9798-71bd8153d0fe\n",
      "Waiting for completion...Job ID: 1f588a35-792a-438c-bad7-526459fcad0e\n",
      "Waiting for completion... ✅ Done!\n",
      "✅ Saved as text: 신라스테이_여수_호텔안내자료_parsed_20250806_182406.txt\n",
      "  ✅ 신라스테이_여수_호텔안내자료.pdf: 14 pages, 3,223 words\n",
      "      → Saved as: 신라스테이_여수_호텔안내자료_parsed_20250806_182406.txt\n",
      " ✅ Done!\n",
      "✅ Saved as text: 삼성 재무제표_parsed_20250806_182410.txt\n",
      "  ✅ 삼성 재무제표.pdf: 2 pages, 679 words\n",
      "      → Saved as: 삼성 재무제표_parsed_20250806_182410.txt\n",
      " ✅ Done!\n",
      "✅ Saved as text: 삼성 청소기 퀵 가이드_parsed_20250806_182414.txt\n",
      "  ✅ 삼성 청소기 퀵 가이드.pdf: 2 pages, 1,974 words\n",
      "      → Saved as: 삼성 청소기 퀵 가이드_parsed_20250806_182414.txt\n",
      "\n",
      "📊 Batch Processing Summary:\n",
      "  • Processed: 3/3 PDFs successfully\n",
      "  • Total pages: 18\n",
      "  • Total words: 5,876\n",
      "\n",
      "💾 Saved Files:\n",
      "  • 신라스테이_여수_호텔안내자료_parsed_20250806_182406.txt\n",
      "  • 삼성 재무제표_parsed_20250806_182410.txt\n",
      "  • 삼성 청소기 퀵 가이드_parsed_20250806_182414.txt\n",
      "✅ Combined all PDFs into: all_pdfs_combined_20250806_182414.txt\n"
     ]
    }
   ],
   "source": [
    "def batch_process_and_save_pdfs(directory_path, max_workers=3, api_key=API_KEY, api_base_url=API_BASE_URL, save_format='txt'):\n",
    "    \"\"\"Process all PDFs in a directory and save each one.\"\"\"\n",
    "    # Check if directory exists\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"Directory not found: {directory_path}\")\n",
    "        return {}\n",
    "    \n",
    "    # Find all PDF files\n",
    "    pdf_files = [\n",
    "        os.path.join(directory_path, f)\n",
    "        for f in os.listdir(directory_path)\n",
    "        if f.lower().endswith('.pdf')\n",
    "    ]\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(f\"No PDF files found in {directory_path}\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"\\n📁 Found {len(pdf_files)} PDF files to process\")\n",
    "    for pdf in pdf_files:\n",
    "        print(f\"  • {os.path.basename(pdf)}\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    def process_and_save_single_pdf(file_path):\n",
    "        \"\"\"Process a single PDF file and save it.\"\"\"\n",
    "        try:\n",
    "            # Parse the document\n",
    "            pages = parse_document(file_path, api_key, api_base_url)\n",
    "            \n",
    "            # Save the parsed content\n",
    "            base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            saved_file = save_parsed_content(pages, base_name, save_format)\n",
    "            \n",
    "            return {\n",
    "                'status': 'success',\n",
    "                'file': os.path.basename(file_path),\n",
    "                'pages': len(pages),\n",
    "                'words': sum(len(p['content'].split()) for p in pages),\n",
    "                'chars': sum(len(p['content']) for p in pages),\n",
    "                'saved_as': saved_file,\n",
    "                'content': pages  # Store the actual content if needed\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'file': os.path.basename(file_path),\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    # Process PDFs concurrently\n",
    "    print(\"\\n⏳ Processing and saving PDFs...\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_file = {\n",
    "            executor.submit(process_and_save_single_pdf, pdf): pdf\n",
    "            for pdf in pdf_files\n",
    "        }\n",
    "        \n",
    "        for future in as_completed(future_to_file):\n",
    "            result = future.result()\n",
    "            results[result['file']] = result\n",
    "            \n",
    "            # Show progress\n",
    "            if result['status'] == 'success':\n",
    "                print(f\"  ✅ {result['file']}: {result['pages']} pages, {result['words']:,} words\")\n",
    "                print(f\"      → Saved as: {result['saved_as']}\")\n",
    "            else:\n",
    "                print(f\"  ❌ {result['file']}: {result['error']}\")\n",
    "    \n",
    "    # Summary\n",
    "    successful = sum(1 for r in results.values() if r['status'] == 'success')\n",
    "    total_pages = sum(r.get('pages', 0) for r in results.values())\n",
    "    total_words = sum(r.get('words', 0) for r in results.values())\n",
    "    \n",
    "    print(f\"\\n📊 Batch Processing Summary:\")\n",
    "    print(f\"  • Processed: {successful}/{len(pdf_files)} PDFs successfully\")\n",
    "    print(f\"  • Total pages: {total_pages:,}\")\n",
    "    print(f\"  • Total words: {total_words:,}\")\n",
    "    print(f\"\\n💾 Saved Files:\")\n",
    "    for result in results.values():\n",
    "        if result['status'] == 'success' and 'saved_as' in result:\n",
    "            print(f\"  • {result['saved_as']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Process and save all PDFs in multiple formats\n",
    "def batch_process_all_formats(directory_path, api_key=API_KEY):\n",
    "    \"\"\"Process PDFs and save in all available formats.\"\"\"\n",
    "    formats = ['txt', 'json', 'md']\n",
    "    all_results = {}\n",
    "    \n",
    "    for fmt in formats:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"📄 Saving all PDFs as {fmt.upper()} format\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        results = batch_process_and_save_pdfs(\n",
    "            directory_path, \n",
    "            max_workers=3, \n",
    "            api_key=api_key,\n",
    "            save_format=fmt\n",
    "        )\n",
    "        all_results[fmt] = results\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Example usage: Process and save all PDFs\n",
    "example_dir = \"../99_example_docs\"\n",
    "\n",
    "# Option 1: Save all as text files\n",
    "print(\"\\n🚀 Processing and saving all PDFs as text files...\")\n",
    "results_txt = batch_process_and_save_pdfs(example_dir, api_key=API_KEY, save_format='txt')\n",
    "\n",
    "# Option 2: Save all in multiple formats (uncomment to use)\n",
    "# print(\"\\n🚀 Processing and saving all PDFs in all formats...\")\n",
    "# all_format_results = batch_process_all_formats(example_dir, api_key=API_KEY)\n",
    "\n",
    "# Function to save all PDFs combined into one file\n",
    "def save_all_pdfs_combined(results, output_filename=\"all_pdfs_combined\"):\n",
    "    \"\"\"Combine all successfully parsed PDFs into a single file.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = f\"{output_filename}_{timestamp}.txt\"\n",
    "    \n",
    "    successful_pdfs = [r for r in results.values() if r['status'] == 'success' and 'content' in r]\n",
    "    \n",
    "    if not successful_pdfs:\n",
    "        print(\"No successfully parsed PDFs to combine\")\n",
    "        return None\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"# Combined PDF Documents\\n\")\n",
    "        f.write(f\"# Parsed on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"# Total documents: {len(successful_pdfs)}\\n\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        for result in successful_pdfs:\n",
    "            f.write(f\"\\n{'='*80}\\n\")\n",
    "            f.write(f\"DOCUMENT: {result['file']}\\n\")\n",
    "            f.write(f\"Pages: {result['pages']}, Words: {result['words']:,}\\n\")\n",
    "            f.write(f\"{'='*80}\\n\\n\")\n",
    "            \n",
    "            for page in result['content']:\n",
    "                f.write(f\"--- Page {page['pageNumber']} ---\\n\")\n",
    "                f.write(page['content'])\n",
    "                f.write(\"\\n\\n\")\n",
    "    \n",
    "    print(f\"✅ Combined all PDFs into: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "# Combine all successfully parsed PDFs (if you want a single combined file)\n",
    "if results_txt:\n",
    "    combined_file = save_all_pdfs_combined(results_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
